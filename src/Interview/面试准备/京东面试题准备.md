# 京东面试准备

### 1.一个标准的 Java Web 请求，从前端到数据库，都经历了哪些环节？

### 面试答案示例

一个标准的 Java Web 请求从前端到数据库，大致经历以下环节：

1. **前端发起请求**
   - 用户操作触发 HTTP 请求（GET/POST）。
   - 请求可携带参数、Cookie、Token 等认证信息。
2. **网络传输**
   - 请求通过 TCP/IP 到达服务器。
   - 如果有负载均衡（如 Nginx），请求先经过反向代理、SSL 解密，并分发到具体后端实例。
3. **Web 容器接收请求**
   - Tomcat/Jetty/Undertow 解析 HTTP 请求，创建 Request/Response 对象。
   - 通过线程池分配线程处理请求。
4. **Spring MVC / Controller 层**
   - DispatcherServlet 接收请求并分发到对应 Controller。
   - Controller 处理请求参数并调用 Service 层。
5. **Service 层业务处理**
   - 处理核心业务逻辑。
   - 调用 DAO 层访问数据库。
   - 可以结合缓存（Redis）或异步线程池优化性能。
6. **DAO / 数据库访问**
   - 使用 MyBatis / JPA / JDBC 执行 SQL。
   - 从数据库连接池获取连接 → 执行 SQL → 返回结果 → 归还连接。
7. **数据库执行**
   - 数据库查询优化器解析 SQL，生成执行计划。
   - 从缓存或磁盘读取数据并返回结果集。
8. **返回前端**
   - Service 层将数据封装为 DTO/VO 返回 Controller。
   - Controller 以 JSON/XML 响应给前端。
   - 前端接收数据并进行渲染。
9. **可选优化环节**
   - **缓存优化**：先查 Redis，减少数据库访问。
   - **异步消息**：通过 RabbitMQ/Kafka 异步处理耗时任务。
   - **监控与日志**：AOP 日志、链路追踪（Sleuth/Zipkin/SkyWalking）。

### 2.详细讲讲 TCP 的三次握手？

**1️⃣ 第一次握手：客户端 → 服务端**

- 客户端发送一个 **SYN** 报文（SYN = 1），表示客户端想建立连接。
- 报文中包含客户端的初始序列号（ISN，Initial Sequence Number）。
- 客户端进入 **SYN_SENT** 状态。

**2️⃣ 第二次握手：服务端 → 客户端**

- 服务端收到 SYN 后，响应 **SYN+ACK** 报文。
  - **SYN = 1** 表示服务端同意建立连接。
  - **ACK** = 客户端的 ISN + 1，确认客户端的 SYN。
- 服务端生成自己的初始序列号（ISN）。
- 服务端进入 **SYN_RECEIVED** 状态。

**3️⃣ 第三次握手：客户端 → 服务端**

- 客户端收到服务端的 SYN+ACK 后，发送 **ACK** 报文给服务端，
  - **ACK** = 服务端的 ISN + 1，确认服务端的 SYN。
- 客户端进入 **ESTABLISHED** 状态。
- 服务端收到 ACK 后，也进入 **ESTABLISHED** 状态。
- 连接建立完成，可以进行数据传输。

------

**三次握手的作用**

1. **确认双方的发送和接收能力**
   - 第一次握手确认客户端能发送报文。
   - 第二次握手确认服务端能接收报文并能发送报文。
   - 第三次握手确认客户端能接收报文。
2. **初始化序列号**
   - 用于后续可靠传输的数据排序、确认。

------

**小知识点 / 面试加分**

- 为什么三次而不是两次？
  - 如果只用两次握手，客户端可能误以为连接建立成功，而服务端没有收到确认，可能导致半开连接。
- 三次握手完成后才能发送数据，保证可靠传输。
- 四次挥手（TCP断开连接）与三次握手类似，但更复杂，因为关闭是双向的。

### 3.你用的哪个 JDK 版本？调过 JVM 参数吗？了解哪些主要参数？

**1️⃣ JDK 版本**

- 我平时开发主要使用 **Java 1.8（Java 8）**，也了解 **Java 11 的新特性**。
- 在项目中，使用 Java 8 Stream API、CompletableFuture、Lambda 表达式等提高代码简洁性和效率。

------

**2️⃣ JVM 参数**

我在生产环境或性能调优中有调优 JVM 参数的经验，主要涉及：

**堆内存相关**

- `-Xms`：初始堆大小
- `-Xmx`：最大堆大小
- `-Xmn`：新生代大小
- `-XX:SurvivorRatio`：Eden 与 Survivor 空间比例

**垃圾回收器相关**

- `-XX:+UseG1GC` / `-XX:+UseParallelGC`：选择垃圾回收器
- `-XX:MaxGCPauseMillis`：G1 最大停顿时间
- `-XX:+PrintGCDetails`、`-Xloggc:gc.log`：打印 GC 日志

**其他常用参数**

- `-XX:+HeapDumpOnOutOfMemoryError`：OOM 时生成堆转储
- `-XX:MetaspaceSize` / `-XX:MaxMetaspaceSize`：元空间大小
- `-XX:+UseCompressedOops`：压缩对象指针

------

💡 **回答加分点**

- 可以结合实际项目讲：比如“在我们的高并发数据处理项目中，我通过调整 `Xmx` 与 `Xms` 减少堆内存扩展频率，通过 G1GC 控制 GC 停顿时间，避免响应延迟。”
- 展示你不仅会设置参数，还能 **分析内存、定位性能瓶颈**。

### 4.了解哪些垃圾回收器和算法？CMS 和 G1 对比过吗？

**1️⃣ 常见垃圾回收器（GC）**

Java 提供多种 GC，主要包括：

| 垃圾回收器                   | 适用场景         | 特点                                              |
| ---------------------------- | ---------------- | ------------------------------------------------- |
| Serial GC                    | 单核或小堆       | 单线程，STW 停顿，简单高效                        |
| Parallel GC                  | 多核、大吞吐量   | 多线程，STW 停顿，优化吞吐量                      |
| CMS（Concurrent Mark-Sweep） | 响应时间敏感应用 | 并发标记-清理，减少 STW 停顿，但可能产生内存碎片  |
| G1（Garbage-First）          | 大堆、低延迟     | 分代收集，按区域回收，控制停顿时间，支持预测性 GC |
| ZGC / Shenandoah             | 超大堆、低延迟   | 基于标记-整理的并发 GC，极低停顿 (<10ms)          |

------

**2️⃣ CMS 与 G1 对比**

| 特性     | CMS                             | G1GC                                     |
| -------- | ------------------------------- | ---------------------------------------- |
| 堆管理   | 年轻代/老年代                   | 区域（Region）划分，不固定代             |
| 收集策略 | 并发标记 + 清理                 | 并发标记 + 并行整理 + 回收优先区域       |
| 停顿     | STW 少，但不固定                | 可预测停顿时间，通过 pause-time 目标控制 |
| 内存碎片 | 可能产生碎片，需要 Full GC 整理 | 区域回收，减少碎片问题                   |
| 使用场景 | 对延迟敏感，中等堆              | 大堆、低延迟、高吞吐量系统               |
| 调优难度 | 较高，需要关注碎片和 Full GC    | 相对容易，提供 pause-time 参数调控停顿   |

**总结**：

- CMS 优势：适合对响应时间敏感的应用，但大堆容易碎片化。
- G1 优势：大堆低延迟，预测性好，已经逐步替代 CMS。

------

💡 **面试答题技巧**
 可以说：“我在生产环境中使用过 G1GC，设置了 `-XX:MaxGCPauseMillis` 控制停顿时间，并通过 JVisualVM / GC 日志分析堆内存和 GC 行为，实现低延迟处理大数据量。”

### 5.遇到过哪些 Java OOM 的场景？怎么处理的？

**1️⃣ 常见 OOM 场景**

| 场景                                     | 说明                                                         |
| ---------------------------------------- | ------------------------------------------------------------ |
| 堆内存溢出（Java heap space）            | 大量对象同时存在或缓存无限增长，导致堆空间耗尽。             |
| 方法区/元空间溢出（Metaspace / PermGen） | 加载类过多或动态生成类过多，导致方法区/元空间耗尽。          |
| 本地内存溢出                             | 大量直接内存（DirectByteBuffer）或 JNI 调用未释放，导致本地内存耗尽。 |
| GC 过频导致 OOM                          | GC 无法及时回收大量对象，造成老年代溢出。                    |

------

**2️⃣ 案例分析（结合项目经验）**

> **项目背景**：在侦查需求统筹系统中，有一个查询功能需要整合多个下级节点数据，每次请求返回的数据量可能非常大。
>
> **问题**：使用 `Java8 Stream` 对大量数据进行流式处理时，如果一次性全部加载到内存中，偶尔会触发 `java.lang.OutOfMemoryError: Java heap space`。

------

**3️⃣ 处理方案**

1. **优化内存使用**
   - 分批次加载数据（分页查询），避免一次性加载大量对象。
   - 对中间状态使用缓存（如 Redis），减少堆内存占用。
2. **调整 JVM 参数**
   - 根据服务器内存调整堆大小：`-Xmx`、`-Xms`。
   - 使用 G1GC 或 CMS，降低 Full GC 停顿，改善内存回收效率。
3. **代码层面优化**
   - 对大对象及时置为 `null`，便于 GC 回收。
   - 避免大量重复对象，可用 Flyweight 或缓存策略。
   - 对大集合使用 `LinkedList` 或流式处理，减少堆占用。
4. **监控与诊断**
   - 使用 `jmap`、`jvisualvm` 或 `Flight Recorder` 分析堆内存。
   - 定期分析 GC 日志，定位内存泄漏或大对象分布。

------

💡 **面试回答示例**

> “在项目中，我遇到过一次大数据量查询导致堆内存溢出的情况。我通过分批加载数据、使用 Redis 缓存中间状态，并优化流式计算逻辑，同时调整 JVM 堆大小和 G1GC 参数，有效解决了 OOM 问题，并保证前端响应速度。后来我还通过 jvisualvm 分析堆，避免类似问题再次发生。”

### 6.ConcurrentHashMap 和 HashMap 的区别

**ConcurrentHashMap 和 HashMap 的区别**

1. **底层结构**
   - **HashMap（JDK 1.8 以后）**：数组 + 链表/红黑树（链表过长时转为红黑树）。
   - **ConcurrentHashMap**：同样是数组 + 链表/红黑树，但在并发控制上更复杂。
2. **线程安全**
   - **HashMap**：线程不安全，多线程环境可能导致数据错乱或死循环。
   - **ConcurrentHashMap**：线程安全，JDK 1.7 采用分段锁，JDK 1.8 改为 **CAS + synchronized 锁桶**，保证并发安全。
3. **并发性能**
   - HashMap 在并发环境下需要额外加锁（如 `Collections.synchronizedMap` 或手动加锁），性能差。
   - ConcurrentHashMap 通过 **无锁读、CAS + 局部加锁写** 来保证高并发下的效率，读多写少场景表现非常好。

------

**为什么要用 ConcurrentHashMap？**

- **线程安全**：避免 HashMap 在多线程下的数据覆盖和异常问题。
- **高性能**：读操作无锁，写操作粒度小，性能比全局加锁要高得多。
- **适用场景**：缓存、配置中心、会话存储等高并发读写的场景。

------

**面试简洁回答（可直接背）**

> “HashMap 线程不安全，底层是数组加链表或红黑树。
>
> ConcurrentHashMap 线程安全，JDK1.7 用分段锁，JDK1.8 之后改成 CAS + synchronized 锁桶机制，读无锁写局部加锁。
>
> 它的优势是既保证线程安全，又能在高并发场景下保持较高性能，所以更适合在缓存或配置管理等并发读写场景使用。”

### 7.Java 里有哪些锁机制？CAS 乐观锁和悲观锁是怎么实现的？

> Java 里常见的锁有 synchronized、ReentrantLock、读写锁和 StampedLock。悲观锁认为并发冲突一定会发生，像 synchronized、ReentrantLock 都属于悲观锁；乐观锁认为冲突不一定发生，所以用 CAS 或版本号来保证数据一致性。CAS 的实现原理是比较内存值和期望值是否一致，一致则更新，不一致就重试。Java 的原子类就是基于 CAS 实现的。

**Java 里的锁机制**

Java 中常见的锁机制主要包括：

1. **synchronized（内置锁/重量级锁）**
   - 作用于方法或代码块，基于 **对象监视器（Monitor）** 实现。
   - JDK1.6 之后引入了锁升级机制：**偏向锁 → 轻量级锁 → 重量级锁**，提高了性能。
2. **ReentrantLock（可重入锁）**
   - JUC 包下的显式锁，功能比 synchronized 更丰富。
   - 支持 **公平锁 / 非公平锁**、**可中断锁**、**尝试获取锁 tryLock()** 等。
3. **读写锁（ReentrantReadWriteLock）**
   - 读写分离，提高并发性能：
     - 读锁共享（多个线程可同时读）。
     - 写锁独占（写操作必须独占）。
4. **StampedLock（JDK 8 引入）**
   - 提供乐观读锁，进一步减少读操作的锁竞争。

------

**乐观锁 vs 悲观锁**

1. **悲观锁**
   - 思想：认为竞争一定会发生，所以在操作数据前先上锁，避免并发冲突。
   - **实现**：
     - Java 中：`synchronized`、`ReentrantLock`。
     - 数据库中：`select ... for update`。
2. **乐观锁**
   - 思想：认为冲突不一定发生，所以先不加锁，更新时通过 **版本号/时间戳** 或 **CAS** 来检测是否有冲突。
   - **实现**：
     - Java 中：`CAS（Compare And Swap）`。
     - 数据库中：乐观锁字段（如 `version` 字段，每次更新时 +1）。

------

**CAS（Compare And Swap）实现原理**

- **CAS**：比较内存中的值是否等于预期值，如果相等就更新为新值，否则失败并重试。
- **原子类（AtomicInteger/AtomicLong）** 就是基于 **CAS + volatile** 实现的。
- 问题：ABA 问题、自旋开销大。解决方案：**AtomicStampedReference** 或引入 **自适应自旋**。

### 8.Java 多线程有哪几种创建和管理方式？了解线程池的哪些参数？

Java 提供了多种方式来创建和管理线程，大体分为以下几类：

1. **直接创建线程**

- **继承 Thread 类**

  ```
  class MyThread extends Thread {
      @Override
      public void run() {
          System.out.println("线程运行中...");
      }
  }
  new MyThread().start();
  ```

- **实现 Runnable 接口**

  ```
  class MyTask implements Runnable {
      @Override
      public void run() {
          System.out.println("线程运行中...");
      }
  }
  new Thread(new MyTask()).start();
  ```

- **实现 Callable 接口 + FutureTask**（能返回结果/抛异常）

  ```
  Callable<Integer> task = () -> 123;
  FutureTask<Integer> futureTask = new FutureTask<>(task);
  new Thread(futureTask).start();
  Integer result = futureTask.get();
  ```

------

2. **使用线程池 (Executor 框架)**

线程池是更推荐的方式，避免频繁创建/销毁线程，提升性能。
 常见工具类：`Executors`、`ThreadPoolExecutor`、`ForkJoinPool`、`ScheduledThreadPool` 等。

```
ExecutorService executor = Executors.newFixedThreadPool(5);
executor.submit(() -> System.out.println("任务执行"));
executor.shutdown();
```

------

3. **更高级的并发工具**

- **CompletableFuture**：支持异步编程、任务组合。
- **ForkJoinPool**：适合大任务拆分成子任务并行处理。
- **ScheduledExecutorService**：定时/周期性任务。

------

**线程池的核心参数 (ThreadPoolExecutor)**

```
public ThreadPoolExecutor(
    int corePoolSize,          // 核心线程数（长期驻留）
    int maximumPoolSize,       // 最大线程数
    long keepAliveTime,        // 空闲线程存活时间
    TimeUnit unit,             // 存活时间单位
    BlockingQueue<Runnable> workQueue, // 任务队列
    ThreadFactory threadFactory,       // 线程工厂（可定制线程名）
    RejectedExecutionHandler handler   // 拒绝策略
)
```

**参数说明**

1. **corePoolSize**
    常驻的核心线程数。线程池创建后即使空闲，也会保留这么多线程。
2. **maximumPoolSize**
    池中允许的最大线程数。超过核心线程数的任务会进入队列，若队列满了，就会新建线程，直到到达 `maximumPoolSize`。
3. **keepAliveTime** + **unit**
    非核心线程（超过 corePoolSize 的线程）空闲多久会被回收。
4. **workQueue（阻塞队列）**
   - `ArrayBlockingQueue`：有界队列，公平/非公平。
   - `LinkedBlockingQueue`：无界/大容量队列。
   - `SynchronousQueue`：不存储任务，必须直接交给线程。
5. **threadFactory**
    用来自定义线程，比如设置线程名、是否为守护线程。
6. **handler（拒绝策略）**
    当线程数达到 `maximumPoolSize` 且队列已满时触发：
   - `AbortPolicy`（默认）：抛异常 `RejectedExecutionException`。
   - `CallerRunsPolicy`：由调用线程执行任务。
   - `DiscardPolicy`：直接丢弃任务，不抛异常。
   - `DiscardOldestPolicy`：丢弃队列中最旧的任务，尝试执行新任务。

------

**常见面试追问**

1. 为什么推荐用 **线程池** 而不是直接 `new Thread()`？
   - 复用线程，减少频繁创建/销毁的开销。
   - 提供统一的任务调度和管理机制。
   - 可以控制最大并发数，避免资源耗尽。
2. 如何设置线程池参数？
   - **CPU 密集型**：`corePoolSize = CPU核数 + 1`
   - **IO 密集型**：`corePoolSize = 2 * CPU核数` 或更高
   - 根据实际业务的 **吞吐量、延迟要求** 来压测调优。

------

✅ 总结：
 Java 多线程有 **3 大类创建方式**：Thread/Runnable/Callable → 线程池 → 高级并发工具。
 线程池的 **7 个关键参数**（核心线程数、最大线程数、存活时间、单位、队列、工厂、拒绝策略）是面试重点，回答时最好结合 **调优思路** 来讲。

### 9.线程池的拒绝策略有哪些？项目里常用哪种？为啥？

Java 线程池在任务队列已满并且线程数达到最大值时，会触发 **拒绝策略（RejectedExecutionHandler）**，JDK 默认提供了 4 种：

1. **AbortPolicy（默认）**
   - 直接抛出 `RejectedExecutionException` 异常，阻止任务继续提交。
   - 使用场景：希望快速发现问题，避免任务被忽略。
2. **CallerRunsPolicy**
   - 由提交任务的线程自己执行该任务。
   - 使用场景：能降低新任务的提交速度，相当于“回压”，常用于流量削峰。
3. **DiscardPolicy**
   - 直接丢弃任务，不抛异常。
   - 使用场景：适合对任务丢失不敏感的场景，比如日志收集。
4. **DiscardOldestPolicy**
   - 丢弃队列中最旧的任务，然后尝试重新提交当前任务。
   - 使用场景：适合“最新数据优先”的场景，比如消息通知。

------

**项目里常用：**
 我常用 **CallerRunsPolicy**，因为它能在任务过载时让提交线程自己去执行任务，从而降低任务的提交速率，起到削峰和保护线程池的作用。这样能避免任务丢失，同时不会无限制扩展队列，比较适合高并发请求的处理场景。

**在需求统筹系统里选择 CallerRunsPolicy 的原因：**

我们的系统在需求统筹和消解过程中，有些任务（例如数据同步、需求状态更新）对一致性和完整性要求比较高，不能轻易丢弃。

- 如果用 **DiscardPolicy** 或 **DiscardOldestPolicy**，有可能导致需求状态更新丢失，前后端数据不一致。
- 如果用 **AbortPolicy**，高并发场景下直接抛异常，会对业务接口造成大量失败，用户体验差。
- **CallerRunsPolicy** 能够在线程池繁忙时，把部分任务交给提交线程去执行，相当于“削峰填谷”，一方面保证了任务不会被丢弃，另一方面也会降低新请求的速度，给系统一个“自我保护”的缓冲。

这种方式特别适合我们系统的需求处理场景：

- **核心数据不丢失**（保证业务逻辑可靠）；
- **系统自动限流**（防止过载导致雪崩）；
- **用户可接受**（延迟稍微增加，总比报错或数据丢失好）。

### 10.开发时用 Spring/Spring Boot 吗？用什么框架操作数据库？

是的，项目开发主要用 **Spring Boot** 作为核心框架，部分场景也用到 **Spring Cloud Alibaba** 做微服务治理。
在数据库层面，主要使用 **MyBatis 和 MyBatis Plus**：

- MyBatis 用于灵活的 SQL 定制，方便处理复杂查询。
- MyBatis Plus 用于简化 CRUD，提高开发效率。
   同时在性能优化方面，会结合 **分页插件、批量操作、SQL 优化（如联合索引、EXPLAIN 分析）** 来保证数据库操作的高效性。

### 11.MyBatis 是怎么实现在同一个事务里操作两个表的？

**1. 核心原理**

MyBatis 本身不管理事务，它依赖 **`SqlSession`** 来执行数据库操作。

- 一个 `SqlSession` 绑定一个 JDBC 连接。
- 在同一个事务中，如果使用同一个 `SqlSession`，对多个表的操作就可以在同一个事务里执行。
- 提交事务时，所有操作统一提交；回滚事务时，所有操作统一回滚。

------

**2. Spring + MyBatis 的实现**

在 Spring Boot 项目中，一般通过 **`@Transactional`** 注解管理事务：

```
@Service
public class OrderService {

    private final OrderMapper orderMapper;
    private final InventoryMapper inventoryMapper;

    public OrderService(OrderMapper orderMapper, InventoryMapper inventoryMapper) {
        this.orderMapper = orderMapper;
        this.inventoryMapper = inventoryMapper;
    }

    @Transactional
    public void placeOrder(Order order, Inventory inventory) {
        // 操作第一个表
        orderMapper.insert(order);

        // 操作第二个表
        inventoryMapper.updateInventory(inventory);

        // 如果中间出现异常，整个事务回滚
    }
}
```

✅ **关键点**：

1. `@Transactional` 作用在 Service 层，Spring 会使用 **AOP 代理**拦截方法。
2. 方法内的多个 Mapper 调用共享同一个数据库连接。
3. 出现异常时，Spring 会调用 JDBC 的回滚机制，保证两张表操作的一致性。

------

**3. 注意事项**

- 只要在同一个事务方法里操作，多个表操作就会在同一事务。
- 异常必须是 **未捕获的 RuntimeException 或 Error**，Spring 才会回滚。
- 不要在事务方法内部调用同一个类的私有方法（AOP 代理不拦截内部调用）。

### 13.开发中用过缓存吗？Redis 用得多吗？了解哪些缓存淘汰策略？

**1️⃣ 项目中使用缓存的场景**

- 在 **侦查需求统筹系统** 中，我使用 **Redis** 缓存中间状态和统计信息，提升查询效率和系统响应速度。
- 对热点数据或跨表联合查询的数据，将结果存入 Redis，设置 **1 分钟刷新策略**，大幅减少数据库压力。
- 缓存不仅加快前端响应，也支持大数据量处理，提高系统吞吐量。

------

**2️⃣ Redis 使用经验**

- 熟悉 Redis 的基本操作（字符串、哈希、列表、集合、有序集合）。

- 使用 Redis 实现高并发场景下的数据缓存、计数、会话存储。
- 实践过缓存更新策略：**先更新数据库，再删除缓存**，保证数据一致性。

------

**3️⃣ 缓存淘汰策略**

Redis 提供多种淘汰策略，应对内存有限和热点数据变化的场景：

| 策略                | 说明                                    |
| ------------------- | --------------------------------------- |
| **noeviction**      | 不淘汰，写入超出 maxmemory 时返回错误   |
| **allkeys-lru**     | 对所有 key 使用 LRU（最近最少使用）淘汰 |
| **volatile-lru**    | 对设置了过期时间的 key 使用 LRU 淘汰    |
| **allkeys-random**  | 对所有 key 随机淘汰                     |
| **volatile-random** | 对设置了过期时间的 key 随机淘汰         |
| **volatile-ttl**    | 优先淘汰 TTL（过期时间）较短的 key      |

✅ **实践选择**：针对热点数据和高并发查询，一般使用 **allkeys-lru** 或 **volatile-lru** 策略，配合合理的过期时间设置，保证缓存命中率和内存利用率。

### 14.更新数据库时，怎么保证缓存和数据一致？怎么防止缓存击穿、雪崩、穿透？

**1️⃣ 缓存与数据库一致性**

在更新数据库时，要保证缓存和数据库一致，一般有以下几种策略：

**（1）先更新数据库，再删除缓存（推荐）**

```
流程：
1. 更新数据库
2. 删除缓存

说明：
- 保证缓存不存旧数据
- 避免先更新缓存导致数据回滚时缓存不一致
```

**（2）先删除缓存，再更新数据库**

```
流程：
1. 删除缓存
2. 更新数据库

说明：
- 可能出现“缓存击穿”问题（缓存被删除，短时间内大量请求落到数据库）
- 需要配合重试或锁机制
```

**（3）直接更新数据库 + 缓存**

- 适合延迟一致性要求高的场景
- 可异步刷新缓存，比如通过 **消息队列** 通知缓存更新

✅ **总结**：推荐 **先更新数据库，再删除缓存** 或 **使用异步消息队列刷新缓存**。

------

**2️⃣ 防止缓存问题**

| 缓存问题                                            | 解决方案                                                     |
| --------------------------------------------------- | ------------------------------------------------------------ |
| **缓存穿透**（查询不存在的数据频繁打到 DB）         | 1. 使用布隆过滤器过滤非法请求    2. 缓存空结果（空对象）     |
| **缓存击穿**（热点数据过期，短时间大量请求打到 DB） | 1. 加互斥锁（Mutex）   2. 先更新数据库再删除缓存   3. 采用单点更新 + 队列异步刷新 |
| **缓存雪崩**（大量 key 同时过期）                   | 1. key 过期时间加随机值，避免同一时间失效   2. 多级缓存架构   3. 热点数据永不过期 + 后台刷新 |

------

**3️⃣ 项目实践示例（结合你的经验）**

- 使用 **Redis 缓存需求数据**，每分钟刷新一次，减少数据库压力
- 对热点查询可加入 **布隆过滤器** 或空对象缓存，防止穿透
- 对关键操作采用 **先更新数据库再删除缓存 + 异步刷新策略**，保证缓存和数据库一致

### 15.Redis 的布隆过滤器原理是啥？

**1️⃣ 基本原理**

1. **位数组**：布隆过滤器内部维护一个固定长度的二进制数组（bit array）。
2. **哈希函数**：使用 **k 个不同的哈希函数**，将元素映射到位数组的 k 个位置。
3. **添加元素**：对元素计算 k 个哈希值，将对应的 bit 位置置为 1。
4. **查询元素**：同样对元素计算 k 个哈希值，检查对应 bit 是否全为 1。
   - 如果全为 1 → 元素可能存在（存在一定的误判概率）。
   - 如果有 0 → 元素一定不存在（没有误判）。

------

**2️⃣ 特点**

- **空间效率高**：比传统哈希表或集合占用内存少。
- **支持快速判断元素是否存在**：查询时间 O(k)。
- **有误判概率**：可能判断一个不存在的元素存在（false positive），但不会漏判存在的元素。

------

**3️⃣ 在 Redis 中的应用**

- **防止缓存穿透**：比如用户输入一个不存在的 ID 查询数据库，布隆过滤器可以先判断是否存在，如果不存在直接返回，减少对数据库的访问。
- **大规模唯一性判断**：适合存储百万级甚至亿级数据而不占用太多内存。

------

**4️⃣ 注意点**

- 布隆过滤器 **不能删除元素**（传统版本），删除可能导致误判。
- 随着元素增多，误判率会增加，需要合理设置 bit 数组长度和哈希函数数量。

### 16.数据库用的 MySQL 吗？为啥 MySQL 用 B+ 树做索引？和 B 树有啥区别？

**MySQL 使用 B+ 树做索引的原因与 B 树区别**

**1️⃣ 为什么 MySQL 使用 B+ 树**

- MySQL InnoDB 存储引擎的 **聚簇索引（主键索引）**和辅助索引都是基于 **B+ 树** 实现的。
- **原因**：
  1. **范围查询效率高**：B+ 树的叶子节点通过链表连接，可以快速进行范围扫描（如 `BETWEEN`、`>`、`<` 查询）。
  2. **磁盘 IO 优化**：B+ 树内部节点只存储 **键值和子节点指针**，叶子节点存储完整数据或行指针，减少磁盘读取次数，提高性能。
  3. **所有数据都在叶子节点**：非叶子节点只做导航，便于顺序访问和批量读取。

------

**2️⃣ B 树与 B+ 树的区别**

| 特性         | B 树                             | B+ 树                                        |
| ------------ | -------------------------------- | -------------------------------------------- |
| 数据存储     | 所有节点（内部和叶子）都存储数据 | 只有叶子节点存储数据，内部节点只存索引       |
| 叶子节点链表 | 无                               | 有指针串联叶子节点，支持顺序遍历             |
| 范围查询     | 较慢，需要遍历多个节点           | 快速顺序访问，范围查询效率高                 |
| 树高度       | 略低于 B+ 树                     | 略高，但更利于磁盘 IO                        |
| 磁盘存储优化 | 一般                             | 内部节点更小，可装入更多索引，提高缓存命中率 |

------

**3️⃣ 总结**

- B+ 树适合数据库索引，因为它**支持高效的范围查询**、**减少磁盘 IO**，在大数据量情况下性能更稳定。
- 面试时可以强调：MySQL 使用 B+ 树是为了 **查询效率和顺序访问优化**。

### 17.页面置换算法

**1️⃣ 先进先出（FIFO, First-In-First-Out）**

- **思想**：最早进入内存的页面最先被替换。
- **优点**：实现简单，维护队列即可。
- **缺点**：不考虑页面使用频率，可能导致“Belady 异常”（增加内存反而增加缺页率）。

------

**2️⃣ 最近最少使用（LRU, Least Recently Used）**

- **思想**：替换 **最近最久未被访问** 的页面。
- **实现**：
  - 使用链表或栈记录访问顺序。
  - 可结合硬件访问位（reference bit）进行近似实现。
- **优点**：比 FIFO 更合理，考虑了实际使用情况。
- **缺点**：维护开销大，时间复杂度可能较高。

------

**3️⃣ 最不常用（LFU, Least Frequently Used）**

- **思想**：替换访问次数最少的页面。
- **实现**：每个页面维护访问计数器，选择计数最小的页面。
- **优点**：适合访问频率集中模式。
- **缺点**：不能反映近期访问趋势，容易淘汰刚进入但近期频繁访问的页面。

------

**4️⃣ 最佳（Optimal）**

- **思想**：替换**将来最长时间不会访问的页面**。
- **优点**：缺页率最低，是理论最优算法。
- **缺点**：需要知道未来访问序列，实际不可实现，仅用于性能评估。

------

**5️⃣ 时钟（Clock）/二次机会（Second Chance）**

- **思想**：类似 FIFO，但给最近使用过的页面一个“二次机会”。
- **实现**：
  - 内存页面形成环形链表（时钟）。
  - 检查访问位（reference bit），为 1 则清零并给页面机会，继续检查下一个页面。
- **优点**：实现简单，近似 LRU，性能较好。

------

**总结**

- **简单替换**：FIFO
- **考虑时间局部性**：LRU、Clock
- **考虑访问频率**：LFU
- **理论最优**：Optimal

### 17.MySQL 是怎么实现事务隔离的？各个隔离级别是怎样的？怎么理解脏读、幻读、可重复读？

> 在 MySQL 中，事务隔离是为了保证多个事务并发执行时互不干扰，确保数据一致性。InnoDB 默认存储引擎通过行级锁和 MVCC 实现事务隔离。
>
> SQL 标准定义了四种隔离级别：
>
> 1. **READ UNCOMMITTED（未提交读）**：允许脏读，即一个事务可以读到另一个未提交事务的数据。
> 2. **READ COMMITTED（提交读）**：只读已提交的数据，避免脏读，但可能出现不可重复读和幻读。
> 3. **REPEATABLE READ（可重复读，MySQL 默认）**：事务开始后读取的数据在事务期间保持一致，避免脏读和不可重复读，但可能出现幻读。InnoDB 使用 Next-Key Lock 防止幻读。
> 4. **SERIALIZABLE（可串行化）**：事务完全串行执行，防止脏读、不可重复读和幻读，但性能开销大。
>
> 常见的异常情况：
>
> - **脏读**：读取到未提交的数据，如果事务回滚就错误了。
> - **不可重复读**：同一条记录在一个事务中被修改过，导致多次读取值不一致。
> - **幻读**：查询结果集中多了或少了行，通常是其他事务插入或删除满足条件的记录。
>
> MySQL 的 InnoDB 引擎利用 MVCC（多版本并发控制）为快照读提供可重复读，并结合行级锁和 Next-Key Lock 避免幻读，从而保证事务隔离和数据一致性。

### 18.MySQL 的 binlog、redo log、undo log 分别是干嘛的？

**在 MySQL/InnoDB 里常见三类日志：binlog、redo log、undo log，它们作用不同：**

1. **binlog（二进制日志，属于 MySQL Server 层）**
   - **作用**：记录所有对数据库的变更（DML、DDL），主要用于数据恢复、主从复制。
   - **特点**：逻辑日志，追加写，跟存储引擎无关。
   - **应用场景**：主从同步、数据库恢复（基于时间点或位置点恢复）。
2. **redo log（重做日志，属于 InnoDB 引擎层）**
   - **作用**：保证事务的持久性（D in ACID）。在事务提交前，先写入 redo log，即使系统崩溃，也能通过 redo log 恢复已提交数据。
   - **特点**：物理日志，记录数据页上的物理修改，循环写。
   - **应用场景**：崩溃恢复（Crash Recovery）。
3. **undo log（回滚日志，属于 InnoDB 引擎层）**
   - **作用**：保证事务的原子性（A in ACID），在事务回滚时用 undo log 撤销已执行的操作；同时配合 MVCC 提供一致性读。
   - **特点**：逻辑日志，记录如何撤销操作，比如 DELETE → INSERT，UPDATE → 反向 UPDATE。
   - **应用场景**：事务回滚、一致性快照读。

**总结：**

- binlog：记录“发生了什么”，用于复制和恢复；
- redo log：保证“已提交的不会丢”，用于崩溃恢复；
- undo log：保证“没提交的能撤回”，用于回滚和 MVCC。

### 19.怎么看 SQL 有没有命中索引？用 EXPLAIN 主要看哪些字段？

**怎么看 SQL 有没有命中索引？**

- **方法一：EXPLAIN 执行计划**（最常用）
- **方法二：慢查询日志**（定位需要优化的 SQL）
- **方法三：SHOW PROFILE**（分析 SQL 具体耗时环节，MySQL 8.0 已废弃）

------

**EXPLAIN 主要看哪些字段？**

1. **id**
   - 查询执行顺序，值越大优先级越高。
2. **select_type**
   - 查询类型，比如 SIMPLE（简单查询）、PRIMARY（主查询）、SUBQUERY（子查询）。
3. **table**
   - 当前执行涉及的表名。
4. **type（最重要）**
   - 访问类型，从好到差：
      `system > const > eq_ref > ref > range > index > ALL`
   - **ALL = 全表扫描**，说明没用上索引，需要关注。
5. **possible_keys**
   - 可能用到的索引。
6. **key**
   - 实际用到的索引，如果是 NULL，说明没命中索引。
7. **key_len**
   - 索引长度，越短越好，能看出索引是否被完全利用。
8. **rows**
   - MySQL 预估需要扫描的行数，越少越好。
9. **Extra**
   - 补充信息，比如：
     - **Using index**：覆盖索引，效率高。
     - **Using where**：需要回表。
     - **Using filesort**：需要额外排序，性能差。
     - **Using temporary**：需要临时表，性能差。

------

✅ **总结面试回答：**

> 判断 SQL 是否命中索引，主要用 EXPLAIN 分析。重点关注 `type`（访问方式，避免 ALL）、`key`（是否用到索引）、`rows`（扫描行数多少）以及 `Extra`（是否有 filesort、temporary）。如果 key 是 NULL 或 type 是 ALL，就说明没有命中索引。

### 20.用过消息队列吗？怎么保证消息的顺序？

✅ **保证消息顺序的常见方案**

1. **单队列 + 单消费者**
   - 所有消息进入同一个队列，只有一个消费者顺序消费。
   - **优点**：实现简单，严格保证顺序。
   - **缺点**：吞吐量低，无法扩展。
2. **分区/分片顺序（推荐做法）**
   - 按照某个业务标识（如订单 ID、用户 ID）做哈希，固定发到同一个队列或分区中。
   - 每个队列再绑定一个消费者，保证同一个业务键的消息顺序。
   - **优点**：既能保证局部顺序，又能提升并发度。
   - **缺点**：需要设计分区规则，避免热点队列。
3. **生产端保证顺序**
   - 在发送时严格按照业务顺序写入 MQ。
4. **消费端保证顺序**
   - 消费端在接收到消息后，先放到内存队列或使用加锁方式处理，确保处理顺序与接收顺序一致。

------

🚀 **在 RabbitMQ 里的实现**

- RabbitMQ 本身**单个 Queue 内消息是有序的**，但前提是：
  - 一个队列只能有一个消费者；
  - 或者多个消费者时，必须保证消息分区规则，让同一业务的消息只被一个消费者处理。

📌 举例：外卖平台场景

> 订单消息（创建、支付、配送、完成）必须顺序消费。可以按照 **订单 ID 哈希分区**，保证同一订单的所有消息进入同一个队列，由同一个消费者顺序消费。这样就不会出现 “配送完成在支付之前” 的问题。

------

✅ 面试回答总结

> 在项目中我用过 RabbitMQ，保证消息顺序主要有两种方式：
>
> - 如果是全局顺序，采用单队列 + 单消费者模式；
> - 如果是局部顺序，比如订单消息，则按照订单 ID 做分区，把同一订单的消息都投递到同一个队列，由固定消费者顺序消费。这样既能保证顺序，又能提升并发度。

### 21. 操作系统里，进程和线程之间怎么传递数据？

> 进程之间通信需要依赖操作系统提供的机制，因为它们的地址空间是隔离的。常见的 IPC 方式有管道、消息队列、共享内存、信号量、信号和套接字。其中共享内存效率最高，但需要配合同步机制。
>
> 而线程属于同一进程，共享内存空间，所以通信更简单，通常通过共享变量、条件变量、信号量或者线程安全队列来实现。线程通信的难点主要是并发同步，而进程通信的难点是如何跨越地址空间。

#### 🔹 进程间通信（IPC）

进程是相互独立的，拥有独立的地址空间，因此需要 **内核提供机制** 才能通信。常见方式：

1. **管道（Pipe/Named Pipe）**
   - 匿名管道：只能在父子进程之间通信，单向。
   - 命名管道（FIFO）：支持无亲缘关系的进程通信。
2. **消息队列（Message Queue）**
   - 内核维护的消息链表，进程间以消息的形式通信。
   - 有结构化数据，避免字节流解析问题。
3. **共享内存（Shared Memory）**
   - 通过映射一块物理内存到多个进程空间来实现。
   - 速度最快，但需要加锁（信号量/互斥锁）保证同步。
4. **信号量（Semaphore）**
   - 本质是计数器，常用于 **进程间同步**，不直接传数据。
5. **信号（Signal）**
   - 异步通知机制，例如 `kill -9` 给进程发信号。
6. **Socket（套接字）**
   - 不仅可以本机进程间通信，也能跨网络通信。
   - 常见于 **分布式系统**。

#### 🔹 线程间通信

线程属于同一个进程，**共享内存空间**，通信比进程简单。

常见方式：

1. **共享变量**（最直接）
   - 所有线程可以读写同一块内存，但需要加锁（互斥锁、读写锁）避免竞态条件。
2. **条件变量（Condition Variable）**
   - 用于线程间的等待与通知。
3. **信号量（Semaphore）**
   - 可用于线程同步/控制并发访问资源数量。
4. **线程安全队列 / BlockingQueue**
   - 在 Java、C++ 中，常用阻塞队列实现生产者-消费者模型。
