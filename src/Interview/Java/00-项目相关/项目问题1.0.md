# 项目场景题

## 项目相关

### 1.怎么把数据库中的100条数据存到redis中，怎么取出？

如果只是为了查询，我会把数据库查出的 100 条记录 序列化为 JSON 后存入 Redis 的 List，每条记录一条元素。
分页查询：Redis 提供 LRANGE 命令，我可以按页获取记录，比如获取前 10 条：LRANGE user_list 0 9，获取第二页 10 条：LRANGE user_list 10 19。
这样做的好处是顺序保留、分页简单、查询速度非常快，而且不涉及对单条字段的更新操作。

### 2.Redis中你的代码是怎么写的？

### 3.数据量级有多大？

日常需要处理上万条记录，我们的项目每天有1000多条需求产生，用户一般情况下会跟踪11天内的数据。

### 4.QPS有多少？

我们项目每天有 1000 多条新需求，用户一般会跟踪 11 天内的数据，大约是 1.1 万条记录。
从写入角度看，写 QPS 很低，不到 1 QPS；
主要压力在查询上，根据我们的用户规模和访问频率，日常查询类的 QPS 大概在 几十到一两百之间，高峰期大约能达到 200 QPS。

### 5.QPS怎么查的？

PSQL:数据库层面，通过 PostgreSQL 的统计表获取某个时间段的查询增量，然后除以秒数得到 QPS。
MySQL：SHOW GLOBAL STATUS LIKE 'Queries';

### 6.为什么上万条数据还要用 Redis？

Redis 不只是用来减轻数据库压力，还能提高响应速度和处理分布式场景下的数据一致性。

### 7.你的项目中为什么要使用redis

**首先是针对高频查询做的优化**
用户会跟踪11天内的需求。比如 需求状态查询、报表统计结果，如果每次都直接查数据库，容易造成数据库压力。我把这些高频查询结果放到 Redis，设置了短期过期时间（ 1 分钟）。
**其次是因为系统是分布式架构的**
需要使用Redis 作为分布式缓存，保证所有节点访问的数据一致，这样可以避免重复查询给数据库带来额外开销。
**然后是需要使用分布式锁进行幂等控制**
在需求提报和状态同步过程中，可能出现并发操作或重复消息消费。
我们使用 Redis的redission实现分布式锁，保证同一份需求不会被多次处理，从而避免数据冲突或不一致。
**用 Redis 控制用户登录状态**
因为如果只依赖本地 Session，在多副本部署下会出现 Session 不共享的问题。把用户 Token 或 Session 信息存放在 Redis，就能让所有服务节点共享登录状态，同时还能利用 Redis 的 TTL 实现自动过期，登录失效。

### 8.说一下你的缓存数据方案？

在项目里，我把最近 11 天的需求信息缓存到 Redis，采用 ZSet + Hash 组合结构。ZSet 存储需求 ID 和创建时间，按时间排序，方便做分页和范围查询；Hash 存每条需求的详细字段。当有新的需求提交或更新时，系统会通过 MQ 异步消息通知重建缓存，重建时用分布式锁保证只有一个实例去刷新，避免缓存雪崩和重复访问数据库。这样既保证了缓存一致性，又提高了查询效率。

### 9.n个需求同时过来要你重建缓存怎么处理？

当很多需求同时过来，需要重建缓存的时候，我不会每条都单独处理，这样太消耗资源。我的做法是先把这些需求的 ID 全部存到 Redis 里，然后启动一个定时任务，每隔五秒去取一些需求 ID，用多线程去批量重建缓存。这样既保证缓存及时更新，又不会让数据库瞬时压力太大。

### 10.重建缓存是怎么重建的？

方案一：【中小数据量】数据提交数据库之后，发送MQ消息携带数据ID去触发缓存更新。
方案二：【高并发大数据量】批量更新，批量写缓存。在redis里存一个批量更新的队列，将需要更新缓存的id放到reids中去，服务的定时任务申请到重建缓存的分布式锁之后进行缓存重建，使用redis的pipeline进行批量缓存更新。

### 11.为什么你的项目中要使用RabbitMQ？

可靠性高：RabbitMQ 支持消息持久化、ACK 确认和死信队列，保证即便服务异常或重启，消息也不会丢失，保证最终一致性。
灵活的路由能力：通过 Exchange（direct/topic/fanout）可以轻松实现不同服务订阅不同类型的消息，例如需求状态更新消息只给缓存服务消费。
异步解耦：业务服务和缓存服务解耦，数据库更新与缓存更新不在同一个线程里，提高系统吞吐量，削峰填谷。
支持延迟和批量处理：可以实现延迟重试、消息累积批量处理（结合 Redis 队列和 Pipeline），保证高并发场景下缓存更新的性能。
成熟稳定、易集成：RabbitMQ 社区成熟，Java 客户端支持好，和我们 Spring Boot + Redis 架构集成简单可靠。

### 12.怎么实现一个延迟队列？

延迟队列是指消息在发送后不会立即被消费者消费，而是在延迟时间到达后才投递给消费者。可以通过 死信队列（DLX）+ TTL 的方式实现：
创建一个 延迟队列，设置消息的过期时间（TTL）和死信交换机（DLX）。
将死信交换机指向 正常的消费队列 的交换机，并设置对应的路由键。
消息在延迟队列中过期后，会被自动转发到正常的消费队列，由消费者消费。

### 13.延迟消息无限存活怎么办？

​		延迟队列中的消息 TTL 到期后，通过死信交换机投递到消费队列时，消息本身的 TTL 已经过期。如果目标队列没有单独配置 TTL，这些消息会在队列中永久存活，直到被消费者消费或队列满触发死信。
为避免消息无限存活，可以在消费队列上设置 队列 TTL（x-message-ttl），限制队列中所有没有 TTL 的消息的最大存活时间。如果消息本身设置了 TTL，则优先使用消息的 TTL。

### 14.先提交数据库事务还是先发MQ消息？

我在项目里采用的方案是先提交数据库，再发送 MQ 消息。
这样至少能保证数据库事务的一致性，不会出现“数据库失败但消息已经发了”的问题。
为了避免消息发送失败造成不一致，我们引入了本地消息表，在事务里把消息写进去，然后有异步任务负责把这条消息发到 MQ，如果失败会不断重试。这样保证了数据库和 MQ 的最终一致性。

### 15.RabbitMQ支持事务消息吗？

​		RabbitMQ 支持事务机制，但是 不支持事务消息（像 RocketMQ 那样的半消息、二阶段提交事务消息机制）。RabbitMQ 不像 RocketMQ、Kafka 那样支持事务消息。它只有普通事务（性能差，不推荐）和发布确认机制。在业务中我们通常会用 本地事务 + 消息表 + 定时任务 来保证最终一致性，或者用 Confirm 模式保证消息可靠投递。

### 16.在项目中为什么采用nacos不使用eruka？

Nacos 不仅能做注册中心，还能做配置中心。方便我们实现配置的热更新
Eureka 已经停止更新了，而 Nacos 社区活跃度高，持续迭代；

## 项目数据量级

### 1.每天大概多少数据，数据表中有多少数据？

> 系统日新增数据量在 3~5 万条，总数据量超过 3000 万条，
>
> 通过分布式架构、索引优化、Redis 缓存和分表策略保证了高并发下的性能稳定。

我们的系统是全国多节点部署（哨位级、处科级、基地级），每天各地会不断录入和上报侦查需求数据。整体来看：

- **每日新增数据量**：大约在 **3～5 万条** 左右，包括需求录入、状态变更、提报记录等。
- **核心表数据总量**：
  - **需求主表（demand）**：约 **800~1000 万条**，记录所有侦查需求信息；
  - **需求处理表（demand_process）**：约 **2000 万条**，每条需求对应多次处理记录；
  - **消息表（message_log）**：约 **300 万条**，用于记录跨节点同步的 MQ 消息发送状态；
  - **状态同步表（status_sync）**：约 **500 万条**，存储三级节点间的状态流转记录。





## 项目中的难点

1. RabbitMQ的消息可靠性问题？



## 自我成长

### 1.在项目中学到了什么？有什么进步？

首先，在**技术能力**上，我对常用的 Java 后端技术栈有了更深入的理解，对分布式系统也有了整体认知。通过项目实践，我学会了独立拆分微服务、设计合理的服务方案，并养成了规范书写代码和持续学习总结的习惯。

其次，在**项目和问题处理能力**上，我提升了独立思考和解决问题的能力。我能够拆解复杂业务流程，独立设计可行方案，并在性能优化方面积累经验，比如 SQL 优化、索引设计和缓存策略应用，实现高效数据处理和快速响应。在分布式系统的数据一致性方面有了一定的理解。

在**团队协作**方面，我学会了如何进行有效的沟通。在这个系统中，我能够与不同模块的同事协调需求、对接接口，确保数据流转顺畅和系统功能的落地。同时，我也学会了在团队讨论中主动提出问题和解决方案，能够快速分析问题原因。这不仅提升了团队协作效率，也让我养成了从系统全局出发考虑问题的思维方式。

















 













