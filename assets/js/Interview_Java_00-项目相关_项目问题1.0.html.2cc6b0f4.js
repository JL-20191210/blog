"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[62683],{66262:(e,s)=>{s.A=(e,s)=>{const a=e.__vccOpts||e;for(const[e,n]of s)a[e]=n;return a}},28890:(e,s,a)=>{a.r(s),a.d(s,{comp:()=>l,data:()=>r});var n=a(20641);const i={},l=(0,a(66262).A)(i,[["render",function(e,s){return(0,n.uX)(),(0,n.CE)("div",null,s[0]||(s[0]=[(0,n.Fv)('<h1 id="项目场景题" tabindex="-1"><a class="header-anchor" href="#项目场景题"><span>项目场景题</span></a></h1><h2 id="项目相关" tabindex="-1"><a class="header-anchor" href="#项目相关"><span>项目相关</span></a></h2><h3 id="_1-怎么把数据库中的100条数据存到redis中-怎么取出" tabindex="-1"><a class="header-anchor" href="#_1-怎么把数据库中的100条数据存到redis中-怎么取出"><span>1.怎么把数据库中的100条数据存到redis中，怎么取出？</span></a></h3><p>如果只是为了查询，我会把数据库查出的 100 条记录 序列化为 JSON 后存入 Redis 的 List，每条记录一条元素。 分页查询：Redis 提供 LRANGE 命令，我可以按页获取记录，比如获取前 10 条：LRANGE user_list 0 9，获取第二页 10 条：LRANGE user_list 10 19。 这样做的好处是顺序保留、分页简单、查询速度非常快，而且不涉及对单条字段的更新操作。</p><h3 id="_2-redis中你的代码是怎么写的" tabindex="-1"><a class="header-anchor" href="#_2-redis中你的代码是怎么写的"><span>2.Redis中你的代码是怎么写的？</span></a></h3><h3 id="_3-数据量级有多大" tabindex="-1"><a class="header-anchor" href="#_3-数据量级有多大"><span>3.数据量级有多大？</span></a></h3><p>日常需要处理上万条记录，我们的项目每天有1000多条需求产生，用户一般情况下会跟踪11天内的数据。</p><h3 id="_4-qps有多少" tabindex="-1"><a class="header-anchor" href="#_4-qps有多少"><span>4.QPS有多少？</span></a></h3><p>我们项目每天有 1000 多条新需求，用户一般会跟踪 11 天内的数据，大约是 1.1 万条记录。 从写入角度看，写 QPS 很低，不到 1 QPS； 主要压力在查询上，根据我们的用户规模和访问频率，日常查询类的 QPS 大概在 几十到一两百之间，高峰期大约能达到 200 QPS。</p><h3 id="_5-qps怎么查的" tabindex="-1"><a class="header-anchor" href="#_5-qps怎么查的"><span>5.QPS怎么查的？</span></a></h3><p>PSQL:数据库层面，通过 PostgreSQL 的统计表获取某个时间段的查询增量，然后除以秒数得到 QPS。 MySQL：SHOW GLOBAL STATUS LIKE &#39;Queries&#39;;</p><h3 id="_6-为什么上万条数据还要用-redis" tabindex="-1"><a class="header-anchor" href="#_6-为什么上万条数据还要用-redis"><span>6.为什么上万条数据还要用 Redis？</span></a></h3><p>Redis 不只是用来减轻数据库压力，还能提高响应速度和处理分布式场景下的数据一致性。</p><h3 id="_7-你的项目中为什么要使用redis" tabindex="-1"><a class="header-anchor" href="#_7-你的项目中为什么要使用redis"><span>7.你的项目中为什么要使用redis</span></a></h3><p><strong>首先是针对高频查询做的优化</strong> 用户会跟踪11天内的需求。比如 需求状态查询、报表统计结果，如果每次都直接查数据库，容易造成数据库压力。我把这些高频查询结果放到 Redis，设置了短期过期时间（ 1 分钟）。 <strong>其次是因为系统是分布式架构的</strong> 需要使用Redis 作为分布式缓存，保证所有节点访问的数据一致，这样可以避免重复查询给数据库带来额外开销。 <strong>然后是需要使用分布式锁进行幂等控制</strong> 在需求提报和状态同步过程中，可能出现并发操作或重复消息消费。 我们使用 Redis的redission实现分布式锁，保证同一份需求不会被多次处理，从而避免数据冲突或不一致。 <strong>用 Redis 控制用户登录状态</strong> 因为如果只依赖本地 Session，在多副本部署下会出现 Session 不共享的问题。把用户 Token 或 Session 信息存放在 Redis，就能让所有服务节点共享登录状态，同时还能利用 Redis 的 TTL 实现自动过期，登录失效。</p><h3 id="_8-说一下你的缓存数据方案" tabindex="-1"><a class="header-anchor" href="#_8-说一下你的缓存数据方案"><span>8.说一下你的缓存数据方案？</span></a></h3><p>在项目里，我把最近 11 天的需求信息缓存到 Redis，采用 ZSet + Hash 组合结构。ZSet 存储需求 ID 和创建时间，按时间排序，方便做分页和范围查询；Hash 存每条需求的详细字段。当有新的需求提交或更新时，系统会通过 MQ 异步消息通知重建缓存，重建时用分布式锁保证只有一个实例去刷新，避免缓存雪崩和重复访问数据库。这样既保证了缓存一致性，又提高了查询效率。</p><h3 id="_9-n个需求同时过来要你重建缓存怎么处理" tabindex="-1"><a class="header-anchor" href="#_9-n个需求同时过来要你重建缓存怎么处理"><span>9.n个需求同时过来要你重建缓存怎么处理？</span></a></h3><p>当很多需求同时过来，需要重建缓存的时候，我不会每条都单独处理，这样太消耗资源。我的做法是先把这些需求的 ID 全部存到 Redis 里，然后启动一个定时任务，每隔五秒去取一些需求 ID，用多线程去批量重建缓存。这样既保证缓存及时更新，又不会让数据库瞬时压力太大。</p><h3 id="_10-重建缓存是怎么重建的" tabindex="-1"><a class="header-anchor" href="#_10-重建缓存是怎么重建的"><span>10.重建缓存是怎么重建的？</span></a></h3><p>方案一：【中小数据量】数据提交数据库之后，发送MQ消息携带数据ID去触发缓存更新。 方案二：【高并发大数据量】批量更新，批量写缓存。在redis里存一个批量更新的队列，将需要更新缓存的id放到reids中去，服务的定时任务申请到重建缓存的分布式锁之后进行缓存重建，使用redis的pipeline进行批量缓存更新。</p><h3 id="_11-为什么你的项目中要使用rabbitmq" tabindex="-1"><a class="header-anchor" href="#_11-为什么你的项目中要使用rabbitmq"><span>11.为什么你的项目中要使用RabbitMQ？</span></a></h3><p>可靠性高：RabbitMQ 支持消息持久化、ACK 确认和死信队列，保证即便服务异常或重启，消息也不会丢失，保证最终一致性。 灵活的路由能力：通过 Exchange（direct/topic/fanout）可以轻松实现不同服务订阅不同类型的消息，例如需求状态更新消息只给缓存服务消费。 异步解耦：业务服务和缓存服务解耦，数据库更新与缓存更新不在同一个线程里，提高系统吞吐量，削峰填谷。 支持延迟和批量处理：可以实现延迟重试、消息累积批量处理（结合 Redis 队列和 Pipeline），保证高并发场景下缓存更新的性能。 成熟稳定、易集成：RabbitMQ 社区成熟，Java 客户端支持好，和我们 Spring Boot + Redis 架构集成简单可靠。</p><h3 id="_12-怎么实现一个延迟队列" tabindex="-1"><a class="header-anchor" href="#_12-怎么实现一个延迟队列"><span>12.怎么实现一个延迟队列？</span></a></h3><p>延迟队列是指消息在发送后不会立即被消费者消费，而是在延迟时间到达后才投递给消费者。可以通过 死信队列（DLX）+ TTL 的方式实现： 创建一个 延迟队列，设置消息的过期时间（TTL）和死信交换机（DLX）。 将死信交换机指向 正常的消费队列 的交换机，并设置对应的路由键。 消息在延迟队列中过期后，会被自动转发到正常的消费队列，由消费者消费。</p><h3 id="_13-延迟消息无限存活怎么办" tabindex="-1"><a class="header-anchor" href="#_13-延迟消息无限存活怎么办"><span>13.延迟消息无限存活怎么办？</span></a></h3><p>​ 延迟队列中的消息 TTL 到期后，通过死信交换机投递到消费队列时，消息本身的 TTL 已经过期。如果目标队列没有单独配置 TTL，这些消息会在队列中永久存活，直到被消费者消费或队列满触发死信。 为避免消息无限存活，可以在消费队列上设置 队列 TTL（x-message-ttl），限制队列中所有没有 TTL 的消息的最大存活时间。如果消息本身设置了 TTL，则优先使用消息的 TTL。</p><h3 id="_14-先提交数据库事务还是先发mq消息" tabindex="-1"><a class="header-anchor" href="#_14-先提交数据库事务还是先发mq消息"><span>14.先提交数据库事务还是先发MQ消息？</span></a></h3><p>我在项目里采用的方案是先提交数据库，再发送 MQ 消息。 这样至少能保证数据库事务的一致性，不会出现“数据库失败但消息已经发了”的问题。 为了避免消息发送失败造成不一致，我们引入了本地消息表，在事务里把消息写进去，然后有异步任务负责把这条消息发到 MQ，如果失败会不断重试。这样保证了数据库和 MQ 的最终一致性。</p><h3 id="_15-rabbitmq支持事务消息吗" tabindex="-1"><a class="header-anchor" href="#_15-rabbitmq支持事务消息吗"><span>15.RabbitMQ支持事务消息吗？</span></a></h3><p>​ RabbitMQ 支持事务机制，但是 不支持事务消息（像 RocketMQ 那样的半消息、二阶段提交事务消息机制）。RabbitMQ 不像 RocketMQ、Kafka 那样支持事务消息。它只有普通事务（性能差，不推荐）和发布确认机制。在业务中我们通常会用 本地事务 + 消息表 + 定时任务 来保证最终一致性，或者用 Confirm 模式保证消息可靠投递。</p><h3 id="_16-在项目中为什么采用nacos不使用eruka" tabindex="-1"><a class="header-anchor" href="#_16-在项目中为什么采用nacos不使用eruka"><span>16.在项目中为什么采用nacos不使用eruka？</span></a></h3><p>Nacos 不仅能做注册中心，还能做配置中心。方便我们实现配置的热更新 Eureka 已经停止更新了，而 Nacos 社区活跃度高，持续迭代；</p><h2 id="项目数据量级" tabindex="-1"><a class="header-anchor" href="#项目数据量级"><span>项目数据量级</span></a></h2><h3 id="_1-每天大概多少数据-数据表中有多少数据" tabindex="-1"><a class="header-anchor" href="#_1-每天大概多少数据-数据表中有多少数据"><span>1.每天大概多少数据，数据表中有多少数据？</span></a></h3><blockquote><p>系统日新增数据量在 3~5 万条，总数据量超过 3000 万条，</p><p>通过分布式架构、索引优化、Redis 缓存和分表策略保证了高并发下的性能稳定。</p></blockquote><p>我们的系统是全国多节点部署（哨位级、处科级、基地级），每天各地会不断录入和上报侦查需求数据。整体来看：</p><ul><li><strong>每日新增数据量</strong>：大约在 <strong>3～5 万条</strong> 左右，包括需求录入、状态变更、提报记录等。</li><li><strong>核心表数据总量</strong>： <ul><li><strong>需求主表（demand）</strong>：约 <strong>800~1000 万条</strong>，记录所有侦查需求信息；</li><li><strong>需求处理表（demand_process）</strong>：约 <strong>2000 万条</strong>，每条需求对应多次处理记录；</li><li><strong>消息表（message_log）</strong>：约 <strong>300 万条</strong>，用于记录跨节点同步的 MQ 消息发送状态；</li><li><strong>状态同步表（status_sync）</strong>：约 <strong>500 万条</strong>，存储三级节点间的状态流转记录。</li></ul></li></ul><h2 id="项目中的难点" tabindex="-1"><a class="header-anchor" href="#项目中的难点"><span>项目中的难点</span></a></h2><ol><li>RabbitMQ的消息可靠性问题？</li></ol><h2 id="自我成长" tabindex="-1"><a class="header-anchor" href="#自我成长"><span>自我成长</span></a></h2><h3 id="_1-在项目中学到了什么-有什么进步" tabindex="-1"><a class="header-anchor" href="#_1-在项目中学到了什么-有什么进步"><span>1.在项目中学到了什么？有什么进步？</span></a></h3><p>首先，在<strong>技术能力</strong>上，我对常用的 Java 后端技术栈有了更深入的理解，对分布式系统也有了整体认知。通过项目实践，我学会了独立拆分微服务、设计合理的服务方案，并养成了规范书写代码和持续学习总结的习惯。</p><p>其次，在<strong>项目和问题处理能力</strong>上，我提升了独立思考和解决问题的能力。我能够拆解复杂业务流程，独立设计可行方案，并在性能优化方面积累经验，比如 SQL 优化、索引设计和缓存策略应用，实现高效数据处理和快速响应。在分布式系统的数据一致性方面有了一定的理解。</p><p>在<strong>团队协作</strong>方面，我学会了如何进行有效的沟通。在这个系统中，我能够与不同模块的同事协调需求、对接接口，确保数据流转顺畅和系统功能的落地。同时，我也学会了在团队讨论中主动提出问题和解决方案，能够快速分析问题原因。这不仅提升了团队协作效率，也让我养成了从系统全局出发考虑问题的思维方式。</p>',45)]))}]]),r=JSON.parse('{"path":"/Interview/Java/00-%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3/%E9%A1%B9%E7%9B%AE%E9%97%AE%E9%A2%981.0.html","title":"项目场景题","lang":"zh-CN","frontmatter":{"gitInclude":[]},"headers":[{"level":2,"title":"项目相关","slug":"项目相关","link":"#项目相关","children":[{"level":3,"title":"1.怎么把数据库中的100条数据存到redis中，怎么取出？","slug":"_1-怎么把数据库中的100条数据存到redis中-怎么取出","link":"#_1-怎么把数据库中的100条数据存到redis中-怎么取出","children":[]},{"level":3,"title":"2.Redis中你的代码是怎么写的？","slug":"_2-redis中你的代码是怎么写的","link":"#_2-redis中你的代码是怎么写的","children":[]},{"level":3,"title":"3.数据量级有多大？","slug":"_3-数据量级有多大","link":"#_3-数据量级有多大","children":[]},{"level":3,"title":"4.QPS有多少？","slug":"_4-qps有多少","link":"#_4-qps有多少","children":[]},{"level":3,"title":"5.QPS怎么查的？","slug":"_5-qps怎么查的","link":"#_5-qps怎么查的","children":[]},{"level":3,"title":"6.为什么上万条数据还要用 Redis？","slug":"_6-为什么上万条数据还要用-redis","link":"#_6-为什么上万条数据还要用-redis","children":[]},{"level":3,"title":"7.你的项目中为什么要使用redis","slug":"_7-你的项目中为什么要使用redis","link":"#_7-你的项目中为什么要使用redis","children":[]},{"level":3,"title":"8.说一下你的缓存数据方案？","slug":"_8-说一下你的缓存数据方案","link":"#_8-说一下你的缓存数据方案","children":[]},{"level":3,"title":"9.n个需求同时过来要你重建缓存怎么处理？","slug":"_9-n个需求同时过来要你重建缓存怎么处理","link":"#_9-n个需求同时过来要你重建缓存怎么处理","children":[]},{"level":3,"title":"10.重建缓存是怎么重建的？","slug":"_10-重建缓存是怎么重建的","link":"#_10-重建缓存是怎么重建的","children":[]},{"level":3,"title":"11.为什么你的项目中要使用RabbitMQ？","slug":"_11-为什么你的项目中要使用rabbitmq","link":"#_11-为什么你的项目中要使用rabbitmq","children":[]},{"level":3,"title":"12.怎么实现一个延迟队列？","slug":"_12-怎么实现一个延迟队列","link":"#_12-怎么实现一个延迟队列","children":[]},{"level":3,"title":"13.延迟消息无限存活怎么办？","slug":"_13-延迟消息无限存活怎么办","link":"#_13-延迟消息无限存活怎么办","children":[]},{"level":3,"title":"14.先提交数据库事务还是先发MQ消息？","slug":"_14-先提交数据库事务还是先发mq消息","link":"#_14-先提交数据库事务还是先发mq消息","children":[]},{"level":3,"title":"15.RabbitMQ支持事务消息吗？","slug":"_15-rabbitmq支持事务消息吗","link":"#_15-rabbitmq支持事务消息吗","children":[]},{"level":3,"title":"16.在项目中为什么采用nacos不使用eruka？","slug":"_16-在项目中为什么采用nacos不使用eruka","link":"#_16-在项目中为什么采用nacos不使用eruka","children":[]}]},{"level":2,"title":"项目数据量级","slug":"项目数据量级","link":"#项目数据量级","children":[{"level":3,"title":"1.每天大概多少数据，数据表中有多少数据？","slug":"_1-每天大概多少数据-数据表中有多少数据","link":"#_1-每天大概多少数据-数据表中有多少数据","children":[]}]},{"level":2,"title":"项目中的难点","slug":"项目中的难点","link":"#项目中的难点","children":[]},{"level":2,"title":"自我成长","slug":"自我成长","link":"#自我成长","children":[{"level":3,"title":"1.在项目中学到了什么？有什么进步？","slug":"_1-在项目中学到了什么-有什么进步","link":"#_1-在项目中学到了什么-有什么进步","children":[]}]}],"readingTime":{"minutes":8.73,"words":2619},"filePathRelative":"Interview/Java/00-项目相关/项目问题1.0.md","excerpt":"\\n<h2>项目相关</h2>\\n<h3>1.怎么把数据库中的100条数据存到redis中，怎么取出？</h3>\\n<p>如果只是为了查询，我会把数据库查出的 100 条记录 序列化为 JSON 后存入 Redis 的 List，每条记录一条元素。\\n分页查询：Redis 提供 LRANGE 命令，我可以按页获取记录，比如获取前 10 条：LRANGE user_list 0 9，获取第二页 10 条：LRANGE user_list 10 19。\\n这样做的好处是顺序保留、分页简单、查询速度非常快，而且不涉及对单条字段的更新操作。</p>\\n<h3>2.Redis中你的代码是怎么写的？</h3>\\n<h3>3.数据量级有多大？</h3>"}')}}]);