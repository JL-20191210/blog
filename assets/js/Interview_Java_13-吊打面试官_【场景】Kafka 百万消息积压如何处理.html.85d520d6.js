"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[63264],{66262:(n,s)=>{s.A=(n,s)=>{const i=n.__vccOpts||n;for(const[n,a]of s)i[n]=a;return i}},28585:(n,s,i)=>{i.r(s),i.d(s,{comp:()=>o,data:()=>c});var a=i(20641);const e=i.p+"assets/img/640-176347397472120.b138c8a0.webp",l=i.p+"assets/img/640-176347400718523.a3994580.webp",r=i.p+"assets/img/640-176347404278926.a390deb1.webp",t=i.p+"assets/img/640-176347404837429.6dbe0ca2.webp",p={},o=(0,i(66262).A)(p,[["render",function(n,s){return(0,a.uX)(),(0,a.CE)("div",null,s[0]||(s[0]=[(0,a.Fv)('<h1 id="kafka-百万消息积压如何处理" tabindex="-1"><a class="header-anchor" href="#kafka-百万消息积压如何处理"><span>Kafka 百万消息积压如何处理</span></a></h1><blockquote><p>它一般由于<strong>代码bug（比如消费逻辑处理有误）</strong>、或者生产者的生产速度大于消费者的消费速度（如大促、抢购等活动期间导致消息数量激增，<strong>或者消费者处理速度极慢</strong>），就可能导致生产环境出现百万、甚至千万的消息积压。</p></blockquote><figure><img src="'+e+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>那么，假设发生kafka百万消息堆积，如何解决呢？</p><ul><li>先排查是不是bug，如果是，要快速修复</li><li>优化消费者代码逻辑</li><li>临时紧急扩容，新建临时topic</li></ul><h2 id="_1-先排查是不是bug-如果是-要快速修复" tabindex="-1"><a class="header-anchor" href="#_1-先排查是不是bug-如果是-要快速修复"><span><strong>1. 先排查是不是bug，如果是，要快速修复</strong></span></a></h2><p>遇到消息积压问题时，我们需要先排查，<strong>是不是有bug产生了</strong>,比如消费者未正确提交偏移量（Offset）。</p><blockquote><p>消费者在处理完消息后未提交偏移量，导致重复消费或消费停滞。进而形成大量消息积压。</p></blockquote><p>给个<strong>伪代码反例</strong>：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>while (true) {</span></span>\n<span class="line"><span>    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(100));</span></span>\n<span class="line"><span>    for (ConsumerRecord&lt;String, String&gt; record : records) {</span></span>\n<span class="line"><span>        process(record);</span></span>\n<span class="line"><span>        // 未提交偏移量</span></span>\n<span class="line"><span>    }</span></span>\n<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在处理完消息后，要正确提交偏移量。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>while (true) {</span></span>\n<span class="line"><span>    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(100));</span></span>\n<span class="line"><span>    for (ConsumerRecord&lt;String, String&gt; record : records) {</span></span>\n<span class="line"><span>        process(record);</span></span>\n<span class="line"><span>    }</span></span>\n<span class="line"><span>    //提交偏移量</span></span>\n<span class="line"><span>    consumer.commitSync();</span></span>\n<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-优化消费者代码逻辑" tabindex="-1"><a class="header-anchor" href="#_2-优化消费者代码逻辑"><span><strong>2. 优化消费者代码逻辑</strong></span></a></h2><p>如果不是bug，那就可能是消费者速度不给力，导致的消息积压。我们可以优化一下消费者代码逻辑。</p><figure><img src="'+l+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>可以使用<strong>多线程处理</strong>，可以减少每条消息的处理时间（比如减少不必要的计算），从而提高消息处理速度。</p><p>假设消费者有<strong>两台</strong>机器，消费者代码优化前是，1秒处理100条消息。代码优化后，<strong>l秒可以处理消息500条</strong>。</p><p>一个小时，可以处理消息：2* 500 * 3600 = 3600 000</p><p>可以发现，如果累积了3百多万消息的话，处理完也要一个小时。如果是生产环境，一些<strong>比较敏感或者特殊</strong>的业务，<strong>是不允许很长的时间延迟的。</strong></p><h2 id="_3-临时紧急扩容-新建临时topic" tabindex="-1"><a class="header-anchor" href="#_3-临时紧急扩容-新建临时topic"><span><strong>3. 临时紧急扩容，新建临时topic</strong></span></a></h2><p>业务紧急的话，我们可以临时紧急扩容，新建临时topic。</p><p>比如原来的topic 只有两个partition分区，因为<strong>消费者处理很耗时等操作</strong>，导致了百万消息积压，这时候需要紧急快速处理。</p><p>这时候，消费者的代码，我们可以做一些调整，就是不再处理其他业务操作。而是<strong>新建临时的topic</strong>，把消息转发到临时的topic，并且partition 分区增加到原来的 10倍</p><figure><img src="'+r+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>然后我们原来消费者业务逻辑处理的代码，放在新的临时消息那里处理。</p><figure><img src="'+t+'" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>等快速消费完积压数据之后，得恢复原先部署的架构，下掉临时消费者，重新用原先的 consumer 机器来消费消息。</p><h2 id="最后" tabindex="-1"><a class="header-anchor" href="#最后"><span><strong>最后</strong></span></a></h2><p>对于线上kafka 消息大量积压的问题，我总结了这几点：</p><ul><li>我们要做好监控和告警，<strong>当消息积压到一定程度的时候，就要告警，通知负责人</strong>，提前处理。</li><li>不要上来就新建临时topic，去快速处理大量积压问题。<strong>应该先排查是不是bug，优化消费者的代码</strong>。</li><li>如果消息设置了超时时间，因为百万消息积压，<strong>没来得及处理就过期清理，可以设置定时任务拉起来重发一下</strong>。</li></ul>',30)]))}]]),c=JSON.parse('{"path":"/Interview/Java/13-%E5%90%8A%E6%89%93%E9%9D%A2%E8%AF%95%E5%AE%98/%E3%80%90%E5%9C%BA%E6%99%AF%E3%80%91Kafka%20%E7%99%BE%E4%B8%87%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86.html","title":"Kafka 百万消息积压如何处理","lang":"zh-CN","frontmatter":{"gitInclude":[]},"headers":[{"level":2,"title":"1. 先排查是不是bug，如果是，要快速修复","slug":"_1-先排查是不是bug-如果是-要快速修复","link":"#_1-先排查是不是bug-如果是-要快速修复","children":[]},{"level":2,"title":"2. 优化消费者代码逻辑","slug":"_2-优化消费者代码逻辑","link":"#_2-优化消费者代码逻辑","children":[]},{"level":2,"title":"3. 临时紧急扩容，新建临时topic","slug":"_3-临时紧急扩容-新建临时topic","link":"#_3-临时紧急扩容-新建临时topic","children":[]},{"level":2,"title":"最后","slug":"最后","link":"#最后","children":[]}],"readingTime":{"minutes":2.97,"words":892},"filePathRelative":"Interview/Java/13-吊打面试官/【场景】Kafka 百万消息积压如何处理.md","excerpt":"\\n<blockquote>\\n<p>它一般由于<strong>代码bug（比如消费逻辑处理有误）</strong>、或者生产者的生产速度大于消费者的消费速度（如大促、抢购等活动期间导致消息数量激增，<strong>或者消费者处理速度极慢</strong>），就可能导致生产环境出现百万、甚至千万的消息积压。</p>\\n</blockquote>\\n<figure><figcaption>图片</figcaption></figure>\\n<p>那么，假设发生kafka百万消息堆积，如何解决呢？</p>\\n<ul>\\n<li>先排查是不是bug，如果是，要快速修复</li>\\n<li>优化消费者代码逻辑</li>\\n<li>临时紧急扩容，新建临时topic</li>\\n</ul>"}')}}]);